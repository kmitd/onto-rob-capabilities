# (msg|srv|act)_type,(msg|srv|act)_name,[listOfCapabilities]
actionlib_msg,GoalID,[General_Action]                                                           #Autonomous capabilities, you can give the robot a goal
actionlib_msg,GoalStatus,[General_Action]                                                       #^^^
actionlib_msg,GoalStatusArray,[General_Action]                                                  #^^^

Directional_Movement (also just sensor measurements, depens on the source) 
geometry_msg,Accel
geometry_msg,AccelStamped
geometry_msg,AccelWithCovariance
geometry_msg,AccelWithCovarianceStamped

Robot_position
geometry_msg,Pose,
geometry_msg,Pose2D
geometry_msg,PoseArray (we can ignore this now, probably)
geometry_msg,PoseStamped
geometry_msg,PoseWithCovariance
geometry_msg,PoseWithCovarianceStamped

Orientation (is it useful to GIVE an orientation?)
Give a generic geometrical information, usually used as a "submessage" in combination with position
as a sensor: i.e. IMU estimates robot orientation
as an input: i.e. goal for a 6dof robot [x, y, z] + [x, y, z, q]
It is better to consider the whole message and maybe the structure of the topic
geometry_msg,Quaternion
geometry_msg,QuaternionStamped

Directional_Movement
Did some research, gyro are usually Vector3, Twist is only directional movement
geometry_msg,Twist
geometry_msg,TwistStamped
geometry_msg,TwistWithCovariance
geometry_msg,TwistWithCovarianceStamped

Map (internal-world) representation
nav_msg,GridCells
nav_msg,MapMetaData
nav_msg,OccupancyGrid

Robot_position, Robot_speed
Odometry it's always a "sensor", it is wrong to use it to command the robot
nav_msg,Odometry
sensor_msg,Imu

Navigation_Movement
nav_msg,Path

Map (internal-world) representation
nav_srv,GetMap

Navigation_Movement
nav_srv,GetPlan

Map (internal-world) representation
nav_srv,SetMap

Map (internal-world) representation
nav_act,GetMap

Self_Sensing, Battery_Sensing
sensor_msg,BatteryState,[Battery_Sensing]

Vision
sensor_msg,CompressedImage
sensor_msg,Image

Light_sensing
sensor_msg,Illuminance,[Light_Sensing]

Body_part_Movement
sensor_msg,JointState

Teleoperation
sensor_msg,Joy
sensor_msg,JoyFeedback
sensor_msg,JoyFeedbackArray

Depth_Sensing
sensor_msg,LaserEcho
sensor_msg,LaserScan

Magnetic_Field_Sensing
sensor_msg,MagneticField

Body_part_Mvt
sensor_msg,MultiDOFJointState

Depth_Sensing
sensor_msg,MultiEchoLaserScan

GPS_Sensing
sensor_msg,NavSatFix
sensor_msg,NavSatStatus

Depth_Sensing
sensor_msg,PointCloud
sensor_msg,PointCloud2
sensor_msg,PointField
sensor_msg,Range

Vision
sensor_msg,RegionOfInterest

Humidity_Sensing
sensor_msg,RelativeHumidity,[Humidity_Sensing]

Temperature_Sensing
sensor_msg,Temperature,[Temperature_Sensing]

Time_Perception
sensor_msg,TimeReference,[Time_Sensing]

Internal_Representation_Shape
shape_msg,Mesh
shape_msg,MeshTriangle
shape_msg,Plane
shape_msg,SolidPrimitive

Vision
stereo_msg,DisparityImage

Body_part_Movement (for now it's ok that the robot can plan something to move a part of its body, and that's a body_part_movement capability)
trajectory_msg,JointTrajectory
trajectory_msg,JointTrajectoryPoint
trajectory_msg,MultiDOFJointTrajectory
trajectory_msg,MultiDOFJointTrajectoryPoint

Navigation_Movement
move_base_msg,MoveBaseResult
move_base_msg,MoveBaseActionResult
move_base_msg,MoveBaseFeedback
move_base_msg,MoveBaseActionFeedback
move_base_msg,MoveBaseActionGoal
move_base_msg,MoveBaseGoal
move_base_msg,MoveBaseAction
move_base_msg,MoveBase